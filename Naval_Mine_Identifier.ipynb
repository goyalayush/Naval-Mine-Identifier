{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to read the dataset.\n",
    "def read_dataset():\n",
    "    df = pd.read_csv(\"/home/ayush/Downloads/sonar.all-data.csv\")\n",
    "    #print(len(df.columns))\n",
    "    X = df[df.columns[0:60]].values\n",
    "    y = df[df.columns[60]]\n",
    "     \n",
    "    #Encode the dependent variable\n",
    "    encoder = LabelEncoder()\n",
    "    encoder.fit(y)\n",
    "    y = encoder.transform(y)\n",
    "    y = one_hot_encode(y)\n",
    "    print(X.shape)\n",
    "    return (X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition Of Encoder Function.\n",
    "def one_hot_encode(labels):\n",
    "    n_labels = len(labels)\n",
    "    n_unique_labels = len(np.unique(labels))\n",
    "    one_hot_encode = np.zeros((n_labels, n_unique_labels))\n",
    "    one_hot_encode[np.arange(n_labels), labels] = 1\n",
    "    return one_hot_encode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(207, 60)\n",
      "(207, 60)\n",
      "(207, 2)\n",
      "(0, 60)\n"
     ]
    }
   ],
   "source": [
    "# Read the Dataset.\n",
    "X, Y = read_dataset()\n",
    "\n",
    "# Shuffle the dataset to mixup the rows.\n",
    "X, Y = shuffle(X, Y, random_state = 1)\n",
    "\n",
    "# Breaking the dataset into testing and training part.\n",
    "train_x, test_x, train_y, test_y = train_test_split(X, Y, test_size = 0, random_state = 415)\n",
    "\n",
    "print(train_x.shape)\n",
    "print(train_y.shape)\n",
    "print(test_x.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of Dimensions  60\n"
     ]
    }
   ],
   "source": [
    "# Parameters to control the manipulation of our model accuracy and cost.\n",
    "learning_rate = 0.3\n",
    "training_epochs = 1000\n",
    "cost_history = np.empty(shape = [1], dtype = float)\n",
    "n_dim = X.shape[1]\n",
    "print(\"Number of Dimensions \", n_dim)\n",
    "n_class = 2\n",
    "model_path = \"home/NMI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Neural Network\n",
    "# Number of neurons\n",
    "# Number of hidden layers\n",
    "n_hidden_1 = 60\n",
    "n_hidden_2 = 60\n",
    "n_hidden_3 = 60\n",
    "n_hidden_4 = 60\n",
    "\n",
    "x = tf.placeholder(tf.float32, [None, n_dim])\n",
    "W = tf.Variable(tf.zeros([n_dim, n_class]))\n",
    "b = tf.Variable(tf.zeros([n_class]))\n",
    "y_ = tf.placeholder(tf.float32, [None, n_class])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definition of Actual Model : MLP\n",
    "def multilayer_perceptron(x, weights, biases):\n",
    "    layer_1 = tf.add(tf.matmul(x, weights['h1']), biases['b1'])\n",
    "    layer_1 = tf.nn.sigmoid(layer_1)\n",
    "    \n",
    "    layer_2 = tf.add(tf.matmul(layer_1, weights['h2']), biases['b2'])\n",
    "    layer_2 = tf.nn.sigmoid(layer_2)\n",
    "    \n",
    "    layer_3 = tf.add(tf.matmul(layer_2, weights['h3']), biases['b3'])\n",
    "    layer_3 = tf.nn.sigmoid(layer_3)\n",
    "    \n",
    "    layer_4 = tf.add(tf.matmul(layer_3, weights['h4']), biases['b4'])\n",
    "    layer_4 = tf.nn.relu(layer_4)\n",
    "    \n",
    "    out_layer = tf.matmul(layer_4, weights['out']) + biases['out']\n",
    "    return out_layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Weights and Biases\n",
    "\n",
    "weights = {\n",
    "    'h1' : tf.Variable(tf.truncated_normal([n_dim, n_hidden_1])),\n",
    "    'h2' : tf.Variable(tf.truncated_normal([n_hidden_1, n_hidden_2])),\n",
    "    'h3' : tf.Variable(tf.truncated_normal([n_hidden_2, n_hidden_3])),\n",
    "    'h4' : tf.Variable(tf.truncated_normal([n_hidden_3, n_hidden_4])),\n",
    "    'out' : tf.Variable(tf.truncated_normal([n_hidden_4, n_class]))    \n",
    "}\n",
    "\n",
    "biases = {\n",
    "    'b1' : tf.Variable(tf.truncated_normal([n_hidden_1])),\n",
    "    'b2' : tf.Variable(tf.truncated_normal([n_hidden_2])),\n",
    "    'b3' : tf.Variable(tf.truncated_normal([n_hidden_3])),\n",
    "    'b4' : tf.Variable(tf.truncated_normal([n_hidden_4])),\n",
    "    'out' : tf.Variable(tf.truncated_normal([n_class]))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize the Variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "saver = tf.train.Saver()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  0  -  cost :  89.563286  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  1  -  cost :  10.88652  - MSE:  nan - Train Accuracy:  0.46376812\n",
      "epoch :  2  -  cost :  13.3107  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  3  -  cost :  0.848984  - MSE:  nan - Train Accuracy:  0.46376812\n",
      "epoch :  4  -  cost :  0.7541836  - MSE:  nan - Train Accuracy:  0.46376812\n",
      "epoch :  5  -  cost :  0.7047248  - MSE:  nan - Train Accuracy:  0.46376812\n",
      "epoch :  6  -  cost :  0.69067776  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  7  -  cost :  0.6896614  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  8  -  cost :  0.68932617  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  9  -  cost :  0.68903065  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  10  -  cost :  0.68877774  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  11  -  cost :  0.6885389  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  12  -  cost :  0.68830156  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  13  -  cost :  0.6880596  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  14  -  cost :  0.6878167  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  15  -  cost :  0.68756133  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  16  -  cost :  0.6872964  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  17  -  cost :  0.68697804  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  18  -  cost :  0.6866426  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  19  -  cost :  0.6863048  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  20  -  cost :  0.68596935  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  21  -  cost :  0.6856513  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  22  -  cost :  0.6853265  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  23  -  cost :  0.6850001  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  24  -  cost :  0.68466437  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  25  -  cost :  0.6842688  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  26  -  cost :  0.6838708  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  27  -  cost :  0.6834745  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  28  -  cost :  0.6830791  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  29  -  cost :  0.682687  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  30  -  cost :  0.6822837  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  31  -  cost :  0.68188417  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  32  -  cost :  0.6814805  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  33  -  cost :  0.68107194  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  34  -  cost :  0.68067193  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  35  -  cost :  0.6802771  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  36  -  cost :  0.6798919  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  37  -  cost :  0.679504  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  38  -  cost :  0.6791118  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  39  -  cost :  0.67871535  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  40  -  cost :  0.67831457  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  41  -  cost :  0.67790896  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  42  -  cost :  0.6774984  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  43  -  cost :  0.67708266  - MSE:  nan - Train Accuracy:  0.5458937\n",
      "epoch :  44  -  cost :  0.6766619  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  45  -  cost :  0.676236  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  46  -  cost :  0.67580366  - MSE:  nan - Train Accuracy:  0.531401\n",
      "epoch :  47  -  cost :  0.6753658  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  48  -  cost :  0.6749227  - MSE:  nan - Train Accuracy:  0.5458937\n",
      "epoch :  49  -  cost :  0.674473  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  50  -  cost :  0.6740168  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  51  -  cost :  0.67355376  - MSE:  nan - Train Accuracy:  0.5458937\n",
      "epoch :  52  -  cost :  0.6730838  - MSE:  nan - Train Accuracy:  0.5410628\n",
      "epoch :  53  -  cost :  0.6726109  - MSE:  nan - Train Accuracy:  0.5458937\n",
      "epoch :  54  -  cost :  0.6721266  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  55  -  cost :  0.671638  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  56  -  cost :  0.67114544  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  57  -  cost :  0.67065936  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  58  -  cost :  0.6701705  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  59  -  cost :  0.6696491  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  60  -  cost :  0.66917264  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  61  -  cost :  0.66862684  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  62  -  cost :  0.66810215  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  63  -  cost :  0.66759247  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  64  -  cost :  0.6670887  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  65  -  cost :  0.66657156  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  66  -  cost :  0.66605854  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  67  -  cost :  0.6655258  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  68  -  cost :  0.6649913  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  69  -  cost :  0.6644546  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  70  -  cost :  0.6639209  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  71  -  cost :  0.6633968  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  72  -  cost :  0.6629072  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  73  -  cost :  0.6624227  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  74  -  cost :  0.66203964  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  75  -  cost :  0.66154534  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  76  -  cost :  0.6613431  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  77  -  cost :  0.6610786  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  78  -  cost :  0.66100705  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  79  -  cost :  0.66215986  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  80  -  cost :  0.66380465  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  81  -  cost :  0.6692925  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  82  -  cost :  0.67470217  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  83  -  cost :  0.68429714  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  84  -  cost :  0.68767935  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  85  -  cost :  0.6898102  - MSE:  nan - Train Accuracy:  0.5072464\n",
      "epoch :  86  -  cost :  0.6886076  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  87  -  cost :  0.6737069  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  88  -  cost :  0.67156005  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  89  -  cost :  0.6624697  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  90  -  cost :  0.6625204  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  91  -  cost :  0.66212624  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  92  -  cost :  0.6638255  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  93  -  cost :  0.6677445  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  94  -  cost :  0.67165196  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  95  -  cost :  0.6766043  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  96  -  cost :  0.6798289  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  97  -  cost :  0.6765236  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  98  -  cost :  0.67707425  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  99  -  cost :  0.6679261  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  100  -  cost :  0.66825825  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  101  -  cost :  0.66021883  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  102  -  cost :  0.66120857  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  103  -  cost :  0.66037506  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  104  -  cost :  0.6632512  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  105  -  cost :  0.66543114  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  106  -  cost :  0.67001206  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  107  -  cost :  0.6714131  - MSE:  nan - Train Accuracy:  0.5845411\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  108  -  cost :  0.6762797  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  109  -  cost :  0.66721994  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  110  -  cost :  0.6671343  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  111  -  cost :  0.6588081  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  112  -  cost :  0.6605825  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  113  -  cost :  0.6572778  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  114  -  cost :  0.6610882  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  115  -  cost :  0.6607282  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  116  -  cost :  0.6659016  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  117  -  cost :  0.6643543  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  118  -  cost :  0.66917557  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  119  -  cost :  0.66216063  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  120  -  cost :  0.6647118  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  121  -  cost :  0.6564345  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  122  -  cost :  0.65886766  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  123  -  cost :  0.655287  - MSE:  nan - Train Accuracy:  0.647343\n",
      "epoch :  124  -  cost :  0.6588689  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  125  -  cost :  0.6586113  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  126  -  cost :  0.6659388  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  127  -  cost :  0.65962154  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  128  -  cost :  0.6639818  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  129  -  cost :  0.6564645  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  130  -  cost :  0.66003615  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  131  -  cost :  0.6525651  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  132  -  cost :  0.65512276  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  133  -  cost :  0.65311795  - MSE:  nan - Train Accuracy:  0.647343\n",
      "epoch :  134  -  cost :  0.6607336  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  135  -  cost :  0.65604615  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  136  -  cost :  0.66229755  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  137  -  cost :  0.65598994  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  138  -  cost :  0.6602893  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  139  -  cost :  0.6538624  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  140  -  cost :  0.65865535  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  141  -  cost :  0.65244526  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  142  -  cost :  0.65712804  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  143  -  cost :  0.652152  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  144  -  cost :  0.6588511  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  145  -  cost :  0.6526625  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  146  -  cost :  0.6587324  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  147  -  cost :  0.6522453  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  148  -  cost :  0.6585257  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  149  -  cost :  0.65197384  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  150  -  cost :  0.6585467  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  151  -  cost :  0.6521355  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  152  -  cost :  0.65809196  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  153  -  cost :  0.6517094  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  154  -  cost :  0.65779245  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  155  -  cost :  0.65112454  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  156  -  cost :  0.6572886  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  157  -  cost :  0.65086865  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  158  -  cost :  0.6571404  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  159  -  cost :  0.6503583  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  160  -  cost :  0.65587753  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  161  -  cost :  0.64920896  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  162  -  cost :  0.65498155  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  163  -  cost :  0.6483179  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  164  -  cost :  0.6543485  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  165  -  cost :  0.64749825  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  166  -  cost :  0.65377116  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  167  -  cost :  0.6459334  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  168  -  cost :  0.6487715  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  169  -  cost :  0.64374083  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  170  -  cost :  0.65122604  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  171  -  cost :  0.64534754  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  172  -  cost :  0.6513575  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  173  -  cost :  0.6460748  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  174  -  cost :  0.65569824  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  175  -  cost :  0.6440726  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  176  -  cost :  0.64241505  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  177  -  cost :  0.6382905  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  178  -  cost :  0.6456824  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  179  -  cost :  0.64320225  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  180  -  cost :  0.65615404  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  181  -  cost :  0.6464301  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  182  -  cost :  0.6486556  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  183  -  cost :  0.6375165  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  184  -  cost :  0.63721544  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  185  -  cost :  0.63388664  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  186  -  cost :  0.64241505  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  187  -  cost :  0.644648  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  188  -  cost :  0.6614457  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  189  -  cost :  0.6471009  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  190  -  cost :  0.64639145  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  191  -  cost :  0.63276976  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  192  -  cost :  0.6314718  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  193  -  cost :  0.6287699  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  194  -  cost :  0.63553125  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  195  -  cost :  0.6389366  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  196  -  cost :  0.6583631  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  197  -  cost :  0.6444716  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  198  -  cost :  0.6426001  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  199  -  cost :  0.6279419  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  200  -  cost :  0.6296898  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  201  -  cost :  0.62409633  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  202  -  cost :  0.6280369  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  203  -  cost :  0.63142496  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  204  -  cost :  0.652207  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  205  -  cost :  0.6459398  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  206  -  cost :  0.65599877  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  207  -  cost :  0.62478673  - MSE:  nan - Train Accuracy:  0.6666667\n",
      "epoch :  208  -  cost :  0.614969  - MSE:  nan - Train Accuracy:  0.647343\n",
      "epoch :  209  -  cost :  0.6078103  - MSE:  nan - Train Accuracy:  0.68115944\n",
      "epoch :  210  -  cost :  0.60961217  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  211  -  cost :  0.6204252  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  212  -  cost :  0.65263987  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  213  -  cost :  0.6633714  - MSE:  nan - Train Accuracy:  0.59903383\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  214  -  cost :  0.68435067  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  215  -  cost :  0.6279871  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  216  -  cost :  0.60513407  - MSE:  nan - Train Accuracy:  0.6956522\n",
      "epoch :  217  -  cost :  0.595772  - MSE:  nan - Train Accuracy:  0.7198068\n",
      "epoch :  218  -  cost :  0.5922519  - MSE:  nan - Train Accuracy:  0.71014494\n",
      "epoch :  219  -  cost :  0.5924761  - MSE:  nan - Train Accuracy:  0.6956522\n",
      "epoch :  220  -  cost :  0.599041  - MSE:  nan - Train Accuracy:  0.6763285\n",
      "epoch :  221  -  cost :  0.62285537  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  222  -  cost :  0.6917948  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  223  -  cost :  0.6835433  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  224  -  cost :  0.6574566  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  225  -  cost :  0.6160414  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  226  -  cost :  0.59888804  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  227  -  cost :  0.5874503  - MSE:  nan - Train Accuracy:  0.71014494\n",
      "epoch :  228  -  cost :  0.57915574  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  229  -  cost :  0.57522064  - MSE:  nan - Train Accuracy:  0.7198068\n",
      "epoch :  230  -  cost :  0.5722785  - MSE:  nan - Train Accuracy:  0.7198068\n",
      "epoch :  231  -  cost :  0.5697118  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  232  -  cost :  0.5671348  - MSE:  nan - Train Accuracy:  0.7294686\n",
      "epoch :  233  -  cost :  0.5645665  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  234  -  cost :  0.5623731  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  235  -  cost :  0.56261563  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  236  -  cost :  0.5768417  - MSE:  nan - Train Accuracy:  0.6956522\n",
      "epoch :  237  -  cost :  0.66861707  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  238  -  cost :  0.849506  - MSE:  nan - Train Accuracy:  0.49275362\n",
      "epoch :  239  -  cost :  0.7580251  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  240  -  cost :  0.65651226  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  241  -  cost :  0.6240684  - MSE:  nan - Train Accuracy:  0.71014494\n",
      "epoch :  242  -  cost :  0.61476094  - MSE:  nan - Train Accuracy:  0.68599033\n",
      "epoch :  243  -  cost :  0.60960644  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  244  -  cost :  0.60433316  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  245  -  cost :  0.5984842  - MSE:  nan - Train Accuracy:  0.7198068\n",
      "epoch :  246  -  cost :  0.59228  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  247  -  cost :  0.5840277  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  248  -  cost :  0.5731377  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  249  -  cost :  0.5626978  - MSE:  nan - Train Accuracy:  0.7198068\n",
      "epoch :  250  -  cost :  0.5528974  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  251  -  cost :  0.5497029  - MSE:  nan - Train Accuracy:  0.7246377\n",
      "epoch :  252  -  cost :  0.56492203  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  253  -  cost :  0.67998016  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  254  -  cost :  0.8135624  - MSE:  nan - Train Accuracy:  0.4879227\n",
      "epoch :  255  -  cost :  0.61183304  - MSE:  nan - Train Accuracy:  0.6666667\n",
      "epoch :  256  -  cost :  0.597178  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  257  -  cost :  0.5892511  - MSE:  nan - Train Accuracy:  0.7246377\n",
      "epoch :  258  -  cost :  0.58463985  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  259  -  cost :  0.578401  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  260  -  cost :  0.5722389  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  261  -  cost :  0.564898  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  262  -  cost :  0.5580677  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  263  -  cost :  0.5535608  - MSE:  nan - Train Accuracy:  0.7294686\n",
      "epoch :  264  -  cost :  0.57052773  - MSE:  nan - Train Accuracy:  0.68599033\n",
      "epoch :  265  -  cost :  0.65256274  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  266  -  cost :  0.7876745  - MSE:  nan - Train Accuracy:  0.47826087\n",
      "epoch :  267  -  cost :  0.5975603  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  268  -  cost :  0.5811381  - MSE:  nan - Train Accuracy:  0.7294686\n",
      "epoch :  269  -  cost :  0.5691672  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  270  -  cost :  0.55927867  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  271  -  cost :  0.55100286  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  272  -  cost :  0.5404231  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  273  -  cost :  0.52966624  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  274  -  cost :  0.520814  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  275  -  cost :  0.51124924  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  276  -  cost :  0.5124159  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  277  -  cost :  0.58798254  - MSE:  nan - Train Accuracy:  0.66183573\n",
      "epoch :  278  -  cost :  1.0165601  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  279  -  cost :  0.8404161  - MSE:  nan - Train Accuracy:  0.46376812\n",
      "epoch :  280  -  cost :  0.71315974  - MSE:  nan - Train Accuracy:  0.46859902\n",
      "epoch :  281  -  cost :  0.67986906  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  282  -  cost :  0.64551055  - MSE:  nan - Train Accuracy:  0.6328502\n",
      "epoch :  283  -  cost :  0.6071945  - MSE:  nan - Train Accuracy:  0.6714976\n",
      "epoch :  284  -  cost :  0.57606  - MSE:  nan - Train Accuracy:  0.7246377\n",
      "epoch :  285  -  cost :  0.55619186  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  286  -  cost :  0.5449033  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  287  -  cost :  0.5375405  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  288  -  cost :  0.5334703  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  289  -  cost :  0.5437222  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  290  -  cost :  0.6330514  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  291  -  cost :  0.8609691  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  292  -  cost :  0.65040064  - MSE:  nan - Train Accuracy:  0.5169082\n",
      "epoch :  293  -  cost :  0.5852474  - MSE:  nan - Train Accuracy:  0.69082123\n",
      "epoch :  294  -  cost :  0.5356127  - MSE:  nan - Train Accuracy:  0.76328504\n",
      "epoch :  295  -  cost :  0.5139231  - MSE:  nan - Train Accuracy:  0.7584541\n",
      "epoch :  296  -  cost :  0.5070465  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  297  -  cost :  0.51826286  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  298  -  cost :  0.6003673  - MSE:  nan - Train Accuracy:  0.6714976\n",
      "epoch :  299  -  cost :  0.7208939  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  300  -  cost :  0.7391353  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  301  -  cost :  0.6226518  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  302  -  cost :  0.5667892  - MSE:  nan - Train Accuracy:  0.76811594\n",
      "epoch :  303  -  cost :  0.54285985  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  304  -  cost :  0.516052  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  305  -  cost :  0.4935004  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  306  -  cost :  0.48758197  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  307  -  cost :  0.49660885  - MSE:  nan - Train Accuracy:  0.7584541\n",
      "epoch :  308  -  cost :  0.582824  - MSE:  nan - Train Accuracy:  0.7004831\n",
      "epoch :  309  -  cost :  0.7999653  - MSE:  nan - Train Accuracy:  0.5748792\n",
      "epoch :  310  -  cost :  0.79626083  - MSE:  nan - Train Accuracy:  0.5603865\n",
      "epoch :  311  -  cost :  0.64844406  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  312  -  cost :  0.579474  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  313  -  cost :  0.5563421  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  314  -  cost :  0.53716403  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  315  -  cost :  0.51687276  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  316  -  cost :  0.49395505  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  317  -  cost :  0.47341844  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  318  -  cost :  0.46421576  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  319  -  cost :  0.45833504  - MSE:  nan - Train Accuracy:  0.79710144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  320  -  cost :  0.45922974  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  321  -  cost :  0.512841  - MSE:  nan - Train Accuracy:  0.7198068\n",
      "epoch :  322  -  cost :  0.8769333  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  323  -  cost :  0.8457152  - MSE:  nan - Train Accuracy:  0.4830918\n",
      "epoch :  324  -  cost :  0.6031923  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  325  -  cost :  0.5546482  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  326  -  cost :  0.54439604  - MSE:  nan - Train Accuracy:  0.76328504\n",
      "epoch :  327  -  cost :  0.5351209  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  328  -  cost :  0.52582324  - MSE:  nan - Train Accuracy:  0.79227054\n",
      "epoch :  329  -  cost :  0.5164641  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  330  -  cost :  0.50769985  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  331  -  cost :  0.4963257  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  332  -  cost :  0.4813656  - MSE:  nan - Train Accuracy:  0.79227054\n",
      "epoch :  333  -  cost :  0.4642677  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  334  -  cost :  0.44479138  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  335  -  cost :  0.45598108  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  336  -  cost :  0.63011324  - MSE:  nan - Train Accuracy:  0.68115944\n",
      "epoch :  337  -  cost :  0.9980649  - MSE:  nan - Train Accuracy:  0.4830918\n",
      "epoch :  338  -  cost :  0.58121514  - MSE:  nan - Train Accuracy:  0.76811594\n",
      "epoch :  339  -  cost :  0.53490245  - MSE:  nan - Train Accuracy:  0.7246377\n",
      "epoch :  340  -  cost :  0.54408544  - MSE:  nan - Train Accuracy:  0.79227054\n",
      "epoch :  341  -  cost :  0.53200704  - MSE:  nan - Train Accuracy:  0.7246377\n",
      "epoch :  342  -  cost :  0.5858364  - MSE:  nan - Train Accuracy:  0.6956522\n",
      "epoch :  343  -  cost :  0.53162986  - MSE:  nan - Train Accuracy:  0.7246377\n",
      "epoch :  344  -  cost :  0.5950716  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  345  -  cost :  0.51034117  - MSE:  nan - Train Accuracy:  0.7584541\n",
      "epoch :  346  -  cost :  0.5437028  - MSE:  nan - Train Accuracy:  0.7584541\n",
      "epoch :  347  -  cost :  0.51396734  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  348  -  cost :  0.57945234  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  349  -  cost :  0.48545307  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  350  -  cost :  0.5181459  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  351  -  cost :  0.5100127  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  352  -  cost :  0.64003557  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  353  -  cost :  0.4675948  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  354  -  cost :  0.4676303  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  355  -  cost :  0.45976678  - MSE:  nan - Train Accuracy:  0.7584541\n",
      "epoch :  356  -  cost :  0.5637611  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  357  -  cost :  0.6709657  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  358  -  cost :  0.7281822  - MSE:  nan - Train Accuracy:  0.49275362\n",
      "epoch :  359  -  cost :  0.6132889  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  360  -  cost :  0.5061972  - MSE:  nan - Train Accuracy:  0.8067633\n",
      "epoch :  361  -  cost :  0.4460927  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  362  -  cost :  0.4239915  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  363  -  cost :  0.419372  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  364  -  cost :  0.46450043  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  365  -  cost :  0.7588553  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  366  -  cost :  0.8203375  - MSE:  nan - Train Accuracy:  0.4830918\n",
      "epoch :  367  -  cost :  0.59483576  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  368  -  cost :  0.5043586  - MSE:  nan - Train Accuracy:  0.81642514\n",
      "epoch :  369  -  cost :  0.47834468  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  370  -  cost :  0.45761886  - MSE:  nan - Train Accuracy:  0.82125604\n",
      "epoch :  371  -  cost :  0.43700582  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  372  -  cost :  0.4134026  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  373  -  cost :  0.39065292  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  374  -  cost :  0.38134697  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  375  -  cost :  0.4032211  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  376  -  cost :  0.6448538  - MSE:  nan - Train Accuracy:  0.7004831\n",
      "epoch :  377  -  cost :  1.1354209  - MSE:  nan - Train Accuracy:  0.47826087\n",
      "epoch :  378  -  cost :  0.5752451  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  379  -  cost :  0.49749127  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  380  -  cost :  0.4798043  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  381  -  cost :  0.48441035  - MSE:  nan - Train Accuracy:  0.76811594\n",
      "epoch :  382  -  cost :  0.5260661  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  383  -  cost :  0.49277773  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  384  -  cost :  0.5544326  - MSE:  nan - Train Accuracy:  0.68599033\n",
      "epoch :  385  -  cost :  0.44568273  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  386  -  cost :  0.5279578  - MSE:  nan - Train Accuracy:  0.68599033\n",
      "epoch :  387  -  cost :  0.66711795  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  388  -  cost :  0.6932152  - MSE:  nan - Train Accuracy:  0.52657\n",
      "epoch :  389  -  cost :  0.6041909  - MSE:  nan - Train Accuracy:  0.62801933\n",
      "epoch :  390  -  cost :  0.4691188  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  391  -  cost :  0.39693305  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  392  -  cost :  0.40577167  - MSE:  nan - Train Accuracy:  0.82125604\n",
      "epoch :  393  -  cost :  0.5781059  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  394  -  cost :  1.010005  - MSE:  nan - Train Accuracy:  0.49758455\n",
      "epoch :  395  -  cost :  0.49447948  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  396  -  cost :  0.45399368  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  397  -  cost :  0.4375188  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  398  -  cost :  0.42499655  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  399  -  cost :  0.4121798  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  400  -  cost :  0.40695122  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  401  -  cost :  0.41194713  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  402  -  cost :  0.5119561  - MSE:  nan - Train Accuracy:  0.69082123\n",
      "epoch :  403  -  cost :  0.5111435  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  404  -  cost :  0.67450255  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  405  -  cost :  0.42829728  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  406  -  cost :  0.3978843  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  407  -  cost :  0.39677554  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  408  -  cost :  0.40885818  - MSE:  nan - Train Accuracy:  0.79227054\n",
      "epoch :  409  -  cost :  0.5651928  - MSE:  nan - Train Accuracy:  0.6714976\n",
      "epoch :  410  -  cost :  0.5818084  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  411  -  cost :  0.64653236  - MSE:  nan - Train Accuracy:  0.5458937\n",
      "epoch :  412  -  cost :  0.49786347  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  413  -  cost :  0.38667795  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  414  -  cost :  0.35701117  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  415  -  cost :  0.34260648  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  416  -  cost :  0.3626768  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  417  -  cost :  0.541805  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  418  -  cost :  0.9458316  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  419  -  cost :  0.47764358  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  420  -  cost :  0.43046162  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  421  -  cost :  0.41227266  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  422  -  cost :  0.39783725  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  423  -  cost :  0.38648483  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  424  -  cost :  0.37627438  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  425  -  cost :  0.3804082  - MSE:  nan - Train Accuracy:  0.85024154\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  426  -  cost :  0.4041857  - MSE:  nan - Train Accuracy:  0.79227054\n",
      "epoch :  427  -  cost :  0.5926419  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  428  -  cost :  0.41272157  - MSE:  nan - Train Accuracy:  0.8067633\n",
      "epoch :  429  -  cost :  0.47026983  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  430  -  cost :  0.4032717  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  431  -  cost :  0.517997  - MSE:  nan - Train Accuracy:  0.6714976\n",
      "epoch :  432  -  cost :  0.4312184  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  433  -  cost :  0.53202516  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  434  -  cost :  0.36880574  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  435  -  cost :  0.36088493  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  436  -  cost :  0.4003542  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  437  -  cost :  0.6421729  - MSE:  nan - Train Accuracy:  0.6376812\n",
      "epoch :  438  -  cost :  0.5601557  - MSE:  nan - Train Accuracy:  0.6956522\n",
      "epoch :  439  -  cost :  0.57845855  - MSE:  nan - Train Accuracy:  0.6086956\n",
      "epoch :  440  -  cost :  0.43092784  - MSE:  nan - Train Accuracy:  0.81642514\n",
      "epoch :  441  -  cost :  0.35131055  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  442  -  cost :  0.33642256  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  443  -  cost :  0.35603896  - MSE:  nan - Train Accuracy:  0.82125604\n",
      "epoch :  444  -  cost :  0.5847264  - MSE:  nan - Train Accuracy:  0.68115944\n",
      "epoch :  445  -  cost :  0.8146151  - MSE:  nan - Train Accuracy:  0.6038647\n",
      "epoch :  446  -  cost :  0.6539042  - MSE:  nan - Train Accuracy:  0.5072464\n",
      "epoch :  447  -  cost :  0.56019694  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  448  -  cost :  0.47436133  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  449  -  cost :  0.39772904  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  450  -  cost :  0.35097972  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  451  -  cost :  0.3221458  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  452  -  cost :  0.3069972  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  453  -  cost :  0.32243693  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  454  -  cost :  0.4962371  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  455  -  cost :  1.2749982  - MSE:  nan - Train Accuracy:  0.57004833\n",
      "epoch :  456  -  cost :  0.65432584  - MSE:  nan - Train Accuracy:  0.4879227\n",
      "epoch :  457  -  cost :  0.5974683  - MSE:  nan - Train Accuracy:  0.66183573\n",
      "epoch :  458  -  cost :  0.5188652  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  459  -  cost :  0.46923667  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  460  -  cost :  0.42886353  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  461  -  cost :  0.40188602  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  462  -  cost :  0.39746684  - MSE:  nan - Train Accuracy:  0.82125604\n",
      "epoch :  463  -  cost :  0.5190449  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  464  -  cost :  1.1645846  - MSE:  nan - Train Accuracy:  0.5555556\n",
      "epoch :  465  -  cost :  1.1259334  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  466  -  cost :  0.58193517  - MSE:  nan - Train Accuracy:  0.76328504\n",
      "epoch :  467  -  cost :  0.49883124  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  468  -  cost :  0.4774614  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  469  -  cost :  0.46069786  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  470  -  cost :  0.4457689  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  471  -  cost :  0.43281764  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  472  -  cost :  0.4219417  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  473  -  cost :  0.4125063  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  474  -  cost :  0.40202302  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  475  -  cost :  0.3938614  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  476  -  cost :  0.3877373  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  477  -  cost :  0.4013513  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  478  -  cost :  0.4265052  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  479  -  cost :  0.5282607  - MSE:  nan - Train Accuracy:  0.65700483\n",
      "epoch :  480  -  cost :  0.33074358  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  481  -  cost :  0.31238103  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  482  -  cost :  0.30176502  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  483  -  cost :  0.30935714  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  484  -  cost :  0.39430326  - MSE:  nan - Train Accuracy:  0.81642514\n",
      "epoch :  485  -  cost :  0.8035947  - MSE:  nan - Train Accuracy:  0.5942029\n",
      "epoch :  486  -  cost :  0.5314581  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  487  -  cost :  0.5959783  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  488  -  cost :  0.4334383  - MSE:  nan - Train Accuracy:  0.81642514\n",
      "epoch :  489  -  cost :  0.35738274  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  490  -  cost :  0.34133288  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  491  -  cost :  0.33551094  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  492  -  cost :  0.42318124  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  493  -  cost :  0.5776236  - MSE:  nan - Train Accuracy:  0.7294686\n",
      "epoch :  494  -  cost :  0.7433227  - MSE:  nan - Train Accuracy:  0.5507246\n",
      "epoch :  495  -  cost :  0.4408288  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  496  -  cost :  0.37516722  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  497  -  cost :  0.34958592  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  498  -  cost :  0.32864058  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  499  -  cost :  0.31380898  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  500  -  cost :  0.31792766  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  501  -  cost :  0.3892487  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  502  -  cost :  0.58911455  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  503  -  cost :  0.8285291  - MSE:  nan - Train Accuracy:  0.5362319\n",
      "epoch :  504  -  cost :  0.43769225  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  505  -  cost :  0.38856298  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  506  -  cost :  0.3713726  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  507  -  cost :  0.36523145  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  508  -  cost :  0.37884757  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  509  -  cost :  0.37760645  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  510  -  cost :  0.44485256  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  511  -  cost :  0.35193262  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  512  -  cost :  0.40847722  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  513  -  cost :  0.43561614  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  514  -  cost :  0.5686857  - MSE:  nan - Train Accuracy:  0.65217394\n",
      "epoch :  515  -  cost :  0.33715406  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  516  -  cost :  0.3099307  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  517  -  cost :  0.2907519  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  518  -  cost :  0.2937205  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  519  -  cost :  0.34261447  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  520  -  cost :  0.570916  - MSE:  nan - Train Accuracy:  0.68115944\n",
      "epoch :  521  -  cost :  0.6626039  - MSE:  nan - Train Accuracy:  0.68115944\n",
      "epoch :  522  -  cost :  0.62224835  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  523  -  cost :  0.49184948  - MSE:  nan - Train Accuracy:  0.71014494\n",
      "epoch :  524  -  cost :  0.38017276  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  525  -  cost :  0.31522834  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  526  -  cost :  0.2745897  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  527  -  cost :  0.2540738  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  528  -  cost :  0.26493028  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  529  -  cost :  0.3820054  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  530  -  cost :  0.7913864  - MSE:  nan - Train Accuracy:  0.647343\n",
      "epoch :  531  -  cost :  0.8612027  - MSE:  nan - Train Accuracy:  0.589372\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  532  -  cost :  0.61002415  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  533  -  cost :  0.49953455  - MSE:  nan - Train Accuracy:  0.7004831\n",
      "epoch :  534  -  cost :  0.38973537  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  535  -  cost :  0.32026455  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  536  -  cost :  0.28610855  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  537  -  cost :  0.2637142  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  538  -  cost :  0.24990638  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  539  -  cost :  0.24302664  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  540  -  cost :  0.23768124  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  541  -  cost :  0.2342682  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  542  -  cost :  0.23271294  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  543  -  cost :  0.24761197  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  544  -  cost :  0.3762771  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  545  -  cost :  0.9231953  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  546  -  cost :  1.0247116  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  547  -  cost :  0.63023573  - MSE:  nan - Train Accuracy:  0.5797101\n",
      "epoch :  548  -  cost :  0.549157  - MSE:  nan - Train Accuracy:  0.66183573\n",
      "epoch :  549  -  cost :  0.46079618  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  550  -  cost :  0.3769341  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  551  -  cost :  0.3128061  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  552  -  cost :  0.27830523  - MSE:  nan - Train Accuracy:  0.90338165\n",
      "epoch :  553  -  cost :  0.26259735  - MSE:  nan - Train Accuracy:  0.90338165\n",
      "epoch :  554  -  cost :  0.27063268  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  555  -  cost :  0.36389533  - MSE:  nan - Train Accuracy:  0.82125604\n",
      "epoch :  556  -  cost :  0.7596063  - MSE:  nan - Train Accuracy:  0.6763285\n",
      "epoch :  557  -  cost :  0.7240645  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  558  -  cost :  0.5132951  - MSE:  nan - Train Accuracy:  0.69082123\n",
      "epoch :  559  -  cost :  0.39132634  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  560  -  cost :  0.3572852  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  561  -  cost :  0.32662743  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  562  -  cost :  0.29293534  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  563  -  cost :  0.27169296  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  564  -  cost :  0.25551224  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  565  -  cost :  0.24747555  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  566  -  cost :  0.24837627  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  567  -  cost :  0.29587862  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  568  -  cost :  0.5236158  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  569  -  cost :  0.8661612  - MSE:  nan - Train Accuracy:  0.59903383\n",
      "epoch :  570  -  cost :  0.45719033  - MSE:  nan - Train Accuracy:  0.7487923\n",
      "epoch :  571  -  cost :  0.3997044  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  572  -  cost :  0.34710714  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  573  -  cost :  0.32039958  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  574  -  cost :  0.29641464  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  575  -  cost :  0.27161747  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  576  -  cost :  0.2524266  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  577  -  cost :  0.24025838  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  578  -  cost :  0.23607124  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  579  -  cost :  0.26686272  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  580  -  cost :  0.47184163  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  581  -  cost :  0.8886752  - MSE:  nan - Train Accuracy:  0.589372\n",
      "epoch :  582  -  cost :  0.41643956  - MSE:  nan - Train Accuracy:  0.76811594\n",
      "epoch :  583  -  cost :  0.35381204  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  584  -  cost :  0.33132687  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  585  -  cost :  0.31788212  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  586  -  cost :  0.2999626  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  587  -  cost :  0.29395938  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  588  -  cost :  0.28875664  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  589  -  cost :  0.3371145  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  590  -  cost :  0.38405403  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  591  -  cost :  0.507455  - MSE:  nan - Train Accuracy:  0.6714976\n",
      "epoch :  592  -  cost :  0.30406505  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  593  -  cost :  0.28855762  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  594  -  cost :  0.26833022  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  595  -  cost :  0.28979215  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  596  -  cost :  0.3298807  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  597  -  cost :  0.516216  - MSE:  nan - Train Accuracy:  0.7004831\n",
      "epoch :  598  -  cost :  0.44583267  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  599  -  cost :  0.4212245  - MSE:  nan - Train Accuracy:  0.73913044\n",
      "epoch :  600  -  cost :  0.26443118  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  601  -  cost :  0.2369172  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  602  -  cost :  0.22267985  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  603  -  cost :  0.21365972  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  604  -  cost :  0.21087544  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  605  -  cost :  0.22657216  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  606  -  cost :  0.34321782  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  607  -  cost :  0.7773742  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  608  -  cost :  0.99131054  - MSE:  nan - Train Accuracy:  0.5169082\n",
      "epoch :  609  -  cost :  0.6231785  - MSE:  nan - Train Accuracy:  0.6135266\n",
      "epoch :  610  -  cost :  0.40351132  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  611  -  cost :  0.33838594  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  612  -  cost :  0.31727964  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  613  -  cost :  0.295723  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  614  -  cost :  0.27971885  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  615  -  cost :  0.26420385  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  616  -  cost :  0.24833198  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  617  -  cost :  0.23558797  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  618  -  cost :  0.22662236  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  619  -  cost :  0.21917546  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  620  -  cost :  0.22299723  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  621  -  cost :  0.27110708  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  622  -  cost :  0.45319209  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  623  -  cost :  0.8254993  - MSE:  nan - Train Accuracy:  0.69082123\n",
      "epoch :  624  -  cost :  0.84575474  - MSE:  nan - Train Accuracy:  0.52657\n",
      "epoch :  625  -  cost :  0.5027459  - MSE:  nan - Train Accuracy:  0.74396133\n",
      "epoch :  626  -  cost :  0.36515388  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  627  -  cost :  0.30220607  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  628  -  cost :  0.27800974  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  629  -  cost :  0.25947946  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  630  -  cost :  0.24181333  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  631  -  cost :  0.2257576  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  632  -  cost :  0.21662039  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  633  -  cost :  0.20927954  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  634  -  cost :  0.2167872  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  635  -  cost :  0.27279106  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  636  -  cost :  0.4802593  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  637  -  cost :  0.7635361  - MSE:  nan - Train Accuracy:  0.71014494\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  638  -  cost :  0.70780814  - MSE:  nan - Train Accuracy:  0.5652174\n",
      "epoch :  639  -  cost :  0.44427595  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  640  -  cost :  0.32449865  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  641  -  cost :  0.26869965  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  642  -  cost :  0.24259916  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  643  -  cost :  0.22424014  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  644  -  cost :  0.21379045  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  645  -  cost :  0.20504865  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  646  -  cost :  0.2040856  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  647  -  cost :  0.22531438  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  648  -  cost :  0.32926023  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  649  -  cost :  0.6639233  - MSE:  nan - Train Accuracy:  0.7536232\n",
      "epoch :  650  -  cost :  0.81552476  - MSE:  nan - Train Accuracy:  0.5845411\n",
      "epoch :  651  -  cost :  0.39300138  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  652  -  cost :  0.30301368  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  653  -  cost :  0.28231412  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  654  -  cost :  0.264572  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  655  -  cost :  0.24959065  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  656  -  cost :  0.2341226  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  657  -  cost :  0.22046694  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  658  -  cost :  0.21112481  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  659  -  cost :  0.20405929  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  660  -  cost :  0.2046611  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  661  -  cost :  0.22328372  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  662  -  cost :  0.3368426  - MSE:  nan - Train Accuracy:  0.8309179\n",
      "epoch :  663  -  cost :  0.6677236  - MSE:  nan - Train Accuracy:  0.6666667\n",
      "epoch :  664  -  cost :  0.5436963  - MSE:  nan - Train Accuracy:  0.76811594\n",
      "epoch :  665  -  cost :  0.509655  - MSE:  nan - Train Accuracy:  0.68115944\n",
      "epoch :  666  -  cost :  0.3235224  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  667  -  cost :  0.2448208  - MSE:  nan - Train Accuracy:  0.90338165\n",
      "epoch :  668  -  cost :  0.22602814  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  669  -  cost :  0.21464446  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  670  -  cost :  0.21849112  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  671  -  cost :  0.24583483  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  672  -  cost :  0.3396255  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  673  -  cost :  0.54662335  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  674  -  cost :  0.64012516  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  675  -  cost :  0.31924427  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  676  -  cost :  0.25811982  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  677  -  cost :  0.23850629  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  678  -  cost :  0.21774673  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  679  -  cost :  0.20201798  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  680  -  cost :  0.19360723  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  681  -  cost :  0.18643555  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  682  -  cost :  0.18112573  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  683  -  cost :  0.17701775  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  684  -  cost :  0.17855258  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  685  -  cost :  0.20987812  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  686  -  cost :  0.39776802  - MSE:  nan - Train Accuracy:  0.82608694\n",
      "epoch :  687  -  cost :  0.92986244  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  688  -  cost :  0.53260404  - MSE:  nan - Train Accuracy:  0.7294686\n",
      "epoch :  689  -  cost :  0.44709796  - MSE:  nan - Train Accuracy:  0.7584541\n",
      "epoch :  690  -  cost :  0.28105524  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  691  -  cost :  0.25945276  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  692  -  cost :  0.24143241  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  693  -  cost :  0.22733991  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  694  -  cost :  0.2118943  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  695  -  cost :  0.19855867  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  696  -  cost :  0.18968847  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  697  -  cost :  0.18471128  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  698  -  cost :  0.18163271  - MSE:  nan - Train Accuracy:  0.9468599\n",
      "epoch :  699  -  cost :  0.18886794  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  700  -  cost :  0.23039371  - MSE:  nan - Train Accuracy:  0.90338165\n",
      "epoch :  701  -  cost :  0.40927976  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  702  -  cost :  0.8437478  - MSE:  nan - Train Accuracy:  0.6231884\n",
      "epoch :  703  -  cost :  0.35846153  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  704  -  cost :  0.34213802  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  705  -  cost :  0.2847028  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  706  -  cost :  0.28175932  - MSE:  nan - Train Accuracy:  0.90338165\n",
      "epoch :  707  -  cost :  0.26376697  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  708  -  cost :  0.27206263  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  709  -  cost :  0.25958747  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  710  -  cost :  0.2891983  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  711  -  cost :  0.27622604  - MSE:  nan - Train Accuracy:  0.8695652\n",
      "epoch :  712  -  cost :  0.37249762  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  713  -  cost :  0.2855919  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  714  -  cost :  0.377005  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  715  -  cost :  0.31098405  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  716  -  cost :  0.36757097  - MSE:  nan - Train Accuracy:  0.7874396\n",
      "epoch :  717  -  cost :  0.25008154  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  718  -  cost :  0.27487606  - MSE:  nan - Train Accuracy:  0.87439615\n",
      "epoch :  719  -  cost :  0.2599816  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  720  -  cost :  0.31696278  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  721  -  cost :  0.34383267  - MSE:  nan - Train Accuracy:  0.81642514\n",
      "epoch :  722  -  cost :  0.46849322  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  723  -  cost :  0.29028028  - MSE:  nan - Train Accuracy:  0.8599034\n",
      "epoch :  724  -  cost :  0.2666939  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  725  -  cost :  0.2317447  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  726  -  cost :  0.22951514  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  727  -  cost :  0.21045816  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  728  -  cost :  0.22277132  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  729  -  cost :  0.24317066  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  730  -  cost :  0.3052271  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  731  -  cost :  0.4189145  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  732  -  cost :  0.4948514  - MSE:  nan - Train Accuracy:  0.705314\n",
      "epoch :  733  -  cost :  0.2586713  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  734  -  cost :  0.22096674  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  735  -  cost :  0.19930573  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  736  -  cost :  0.18604009  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  737  -  cost :  0.18174627  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  738  -  cost :  0.17895152  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  739  -  cost :  0.18328321  - MSE:  nan - Train Accuracy:  0.90338165\n",
      "epoch :  740  -  cost :  0.20828775  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  741  -  cost :  0.27637404  - MSE:  nan - Train Accuracy:  0.8647343\n",
      "epoch :  742  -  cost :  0.49601808  - MSE:  nan - Train Accuracy:  0.7294686\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch :  743  -  cost :  0.6259851  - MSE:  nan - Train Accuracy:  0.76328504\n",
      "epoch :  744  -  cost :  0.56891847  - MSE:  nan - Train Accuracy:  0.6666667\n",
      "epoch :  745  -  cost :  0.32875112  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  746  -  cost :  0.22234346  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  747  -  cost :  0.19228818  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  748  -  cost :  0.17952381  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  749  -  cost :  0.17105411  - MSE:  nan - Train Accuracy:  0.9468599\n",
      "epoch :  750  -  cost :  0.16659468  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  751  -  cost :  0.16345204  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  752  -  cost :  0.16900875  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  753  -  cost :  0.18408139  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  754  -  cost :  0.24546988  - MSE:  nan - Train Accuracy:  0.87922704\n",
      "epoch :  755  -  cost :  0.40840423  - MSE:  nan - Train Accuracy:  0.8067633\n",
      "epoch :  756  -  cost :  0.697443  - MSE:  nan - Train Accuracy:  0.73429954\n",
      "epoch :  757  -  cost :  0.62701225  - MSE:  nan - Train Accuracy:  0.6425121\n",
      "epoch :  758  -  cost :  0.33610305  - MSE:  nan - Train Accuracy:  0.84541065\n",
      "epoch :  759  -  cost :  0.24138655  - MSE:  nan - Train Accuracy:  0.9227053\n",
      "epoch :  760  -  cost :  0.21437335  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  761  -  cost :  0.19002493  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  762  -  cost :  0.17519172  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  763  -  cost :  0.16554648  - MSE:  nan - Train Accuracy:  0.9468599\n",
      "epoch :  764  -  cost :  0.15939726  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  765  -  cost :  0.15449455  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  766  -  cost :  0.15020485  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  767  -  cost :  0.14703912  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  768  -  cost :  0.14800133  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  769  -  cost :  0.16588245  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  770  -  cost :  0.2644178  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  771  -  cost :  0.629886  - MSE:  nan - Train Accuracy:  0.7777778\n",
      "epoch :  772  -  cost :  0.8089052  - MSE:  nan - Train Accuracy:  0.6183575\n",
      "epoch :  773  -  cost :  0.35110843  - MSE:  nan - Train Accuracy:  0.8357488\n",
      "epoch :  774  -  cost :  0.26623097  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  775  -  cost :  0.2395599  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  776  -  cost :  0.22054951  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  777  -  cost :  0.20609352  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  778  -  cost :  0.1931583  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  779  -  cost :  0.17903078  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  780  -  cost :  0.16957642  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  781  -  cost :  0.16722918  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  782  -  cost :  0.17833401  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  783  -  cost :  0.19503607  - MSE:  nan - Train Accuracy:  0.90821254\n",
      "epoch :  784  -  cost :  0.24343348  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  785  -  cost :  0.33046368  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  786  -  cost :  0.57921904  - MSE:  nan - Train Accuracy:  0.68599033\n",
      "epoch :  787  -  cost :  0.40317625  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  788  -  cost :  0.40216315  - MSE:  nan - Train Accuracy:  0.77294683\n",
      "epoch :  789  -  cost :  0.2035792  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  790  -  cost :  0.18007377  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  791  -  cost :  0.16825072  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  792  -  cost :  0.16128744  - MSE:  nan - Train Accuracy:  0.96135265\n",
      "epoch :  793  -  cost :  0.15884799  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  794  -  cost :  0.16530207  - MSE:  nan - Train Accuracy:  0.9468599\n",
      "epoch :  795  -  cost :  0.18437095  - MSE:  nan - Train Accuracy:  0.9178744\n",
      "epoch :  796  -  cost :  0.2448736  - MSE:  nan - Train Accuracy:  0.8888889\n",
      "epoch :  797  -  cost :  0.38080555  - MSE:  nan - Train Accuracy:  0.8019324\n",
      "epoch :  798  -  cost :  0.61778873  - MSE:  nan - Train Accuracy:  0.69082123\n",
      "epoch :  799  -  cost :  0.3386888  - MSE:  nan - Train Accuracy:  0.85024154\n",
      "epoch :  800  -  cost :  0.2991156  - MSE:  nan - Train Accuracy:  0.85507244\n",
      "epoch :  801  -  cost :  0.21018071  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  802  -  cost :  0.18787076  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  803  -  cost :  0.17295414  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  804  -  cost :  0.17008461  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  805  -  cost :  0.17194676  - MSE:  nan - Train Accuracy:  0.93236715\n",
      "epoch :  806  -  cost :  0.18724641  - MSE:  nan - Train Accuracy:  0.92753625\n",
      "epoch :  807  -  cost :  0.19271663  - MSE:  nan - Train Accuracy:  0.9130435\n",
      "epoch :  808  -  cost :  0.23556714  - MSE:  nan - Train Accuracy:  0.8937198\n",
      "epoch :  809  -  cost :  0.3181992  - MSE:  nan - Train Accuracy:  0.8405797\n",
      "epoch :  810  -  cost :  0.5451503  - MSE:  nan - Train Accuracy:  0.71497583\n",
      "epoch :  811  -  cost :  0.3838149  - MSE:  nan - Train Accuracy:  0.79710144\n",
      "epoch :  812  -  cost :  0.35828865  - MSE:  nan - Train Accuracy:  0.81642514\n",
      "epoch :  813  -  cost :  0.18890195  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  814  -  cost :  0.17087047  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  815  -  cost :  0.15883961  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  816  -  cost :  0.15323558  - MSE:  nan - Train Accuracy:  0.96135265\n",
      "epoch :  817  -  cost :  0.1450133  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  818  -  cost :  0.14389326  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  819  -  cost :  0.14715424  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  820  -  cost :  0.17046373  - MSE:  nan - Train Accuracy:  0.93719804\n",
      "epoch :  821  -  cost :  0.22621883  - MSE:  nan - Train Accuracy:  0.884058\n",
      "epoch :  822  -  cost :  0.37723318  - MSE:  nan - Train Accuracy:  0.8115942\n",
      "epoch :  823  -  cost :  0.60110855  - MSE:  nan - Train Accuracy:  0.7826087\n",
      "epoch :  824  -  cost :  0.5882627  - MSE:  nan - Train Accuracy:  0.6714976\n",
      "epoch :  825  -  cost :  0.28089666  - MSE:  nan - Train Accuracy:  0.89855075\n",
      "epoch :  826  -  cost :  0.19862117  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  827  -  cost :  0.17661193  - MSE:  nan - Train Accuracy:  0.9661836\n",
      "epoch :  828  -  cost :  0.16062279  - MSE:  nan - Train Accuracy:  0.9661836\n",
      "epoch :  829  -  cost :  0.14975625  - MSE:  nan - Train Accuracy:  0.95652175\n",
      "epoch :  830  -  cost :  0.14403437  - MSE:  nan - Train Accuracy:  0.9516908\n",
      "epoch :  831  -  cost :  0.13953374  - MSE:  nan - Train Accuracy:  0.96135265\n",
      "epoch :  832  -  cost :  0.13355231  - MSE:  nan - Train Accuracy:  0.942029\n",
      "epoch :  833  -  cost :  0.13441417  - MSE:  nan - Train Accuracy:  0.95652175\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-28-2a3fe865362c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     21\u001b[0m     \u001b[0mpred_y\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtest_x\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0mmse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreduce_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msquare\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpred_y\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mtest_y\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m     \u001b[0mmse_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m     \u001b[0mmse_history\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmse_\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m     \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0msess\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maccuracy\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_x\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mtrain_y\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36mrun\u001b[0;34m(self, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m    927\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    928\u001b[0m       result = self._run(None, fetches, feed_dict, options_ptr,\n\u001b[0;32m--> 929\u001b[0;31m                          run_metadata_ptr)\n\u001b[0m\u001b[1;32m    930\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    931\u001b[0m         \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run\u001b[0;34m(self, handle, fetches, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1150\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mfinal_fetches\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mfinal_targets\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mfeed_dict_tensor\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1151\u001b[0m       results = self._do_run(handle, final_targets, final_fetches,\n\u001b[0;32m-> 1152\u001b[0;31m                              feed_dict_tensor, options, run_metadata)\n\u001b[0m\u001b[1;32m   1153\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1154\u001b[0m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_run\u001b[0;34m(self, handle, target_list, fetch_list, feed_dict, options, run_metadata)\u001b[0m\n\u001b[1;32m   1326\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mhandle\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1327\u001b[0m       return self._do_call(_run_fn, feeds, fetches, targets, options,\n\u001b[0;32m-> 1328\u001b[0;31m                            run_metadata)\n\u001b[0m\u001b[1;32m   1329\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1330\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_prun_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeeds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetches\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_do_call\u001b[0;34m(self, fn, *args)\u001b[0m\n\u001b[1;32m   1332\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_do_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1333\u001b[0m     \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1334\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1335\u001b[0m     \u001b[0;32mexcept\u001b[0m \u001b[0merrors\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mOpError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1336\u001b[0m       \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcompat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mas_text\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_run_fn\u001b[0;34m(feed_dict, fetch_list, target_list, options, run_metadata)\u001b[0m\n\u001b[1;32m   1317\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_extend_graph\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1318\u001b[0m       return self._call_tf_sessionrun(\n\u001b[0;32m-> 1319\u001b[0;31m           options, feed_dict, fetch_list, target_list, run_metadata)\n\u001b[0m\u001b[1;32m   1320\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1321\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_prun_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/ayush/.local/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m_call_tf_sessionrun\u001b[0;34m(self, options, feed_dict, fetch_list, target_list, run_metadata)\u001b[0m\n\u001b[1;32m   1405\u001b[0m     return tf_session.TF_SessionRun_wrapper(\n\u001b[1;32m   1406\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptions\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtarget_list\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1407\u001b[0;31m         run_metadata)\n\u001b[0m\u001b[1;32m   1408\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1409\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_tf_sessionprun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeed_dict\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfetch_list\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Calling the Model\n",
    "y = multilayer_perceptron(x, weights, biases)\n",
    "\n",
    "# Cost Function And Optimizer\n",
    "cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits = y, labels = y_))\n",
    "training_step = tf.train.GradientDescentOptimizer(learning_rate).minimize(cost_function)\n",
    "\n",
    "sess = tf.Session()\n",
    "sess.run(init)\n",
    "\n",
    "mse_history = []\n",
    "accuracy_history = []\n",
    "\n",
    "for epoch in range(training_epochs):\n",
    "    sess.run(training_step, feed_dict = {x: train_x, y_: train_y})\n",
    "    cost = sess.run(cost_function, feed_dict = {x: train_x, y_: train_y})\n",
    "    cost_history = np.append(cost_history, cost)\n",
    "    correct_predicition = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "    accuracy = tf.reduce_mean(tf.cast(correct_predicition, tf.float32))\n",
    "    #print(\"Accuracy: \", sess.run(accuracy, feed_dict = {x: test_x, y: test_y}))\n",
    "    pred_y = sess.run(y, feed_dict = {x: test_x})\n",
    "    mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "    mse_ = sess.run(mse)\n",
    "    mse_history.append(mse_)\n",
    "    accuracy = (sess.run(accuracy, feed_dict = {x: train_x, y_: train_y}))\n",
    "    accuracy_history.append(accuracy)\n",
    "    \n",
    "    print('epoch : ', epoch, ' - ','cost : ', cost, \" - MSE: \", mse_, \"- Train Accuracy: \", accuracy)\n",
    "    \n",
    "save_path = saver.save(sess, model_path)\n",
    "print(\"Model saved in file: %s\" % save_path)\n",
    "\n",
    "# Plotting MSE and Accuracy graph \n",
    "\n",
    "plt.plot(mse_history, 'r')\n",
    "plt.show()\n",
    "plt.plot(accuracy_history)\n",
    "plt.show()\n",
    "\n",
    "# Printing the final Accuracy\n",
    "\n",
    "correct_prediction = tf.equal(tf.argmax(y, 1), tf.argmax(y_, 1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "print(\"Test Accuracy: \", (sess.run(accuracy, feed_dict = {x: test_x, y:test_y})))\n",
    "\n",
    "# Printing the final MSE\n",
    "\n",
    "pred_y = sess.run(y, feed_dict = {x: test_x})\n",
    "mse = tf.reduce_mean(tf.square(pred_y - test_y))\n",
    "print(\"MSE: %.4f\" % sess.run(mse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
